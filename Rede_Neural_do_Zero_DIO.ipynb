{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMYO0aDG8pErj+WuPNp5z4X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carolhcs/ML-Engineering-Data-Science/blob/main/Rede_Neural_do_Zero_DIO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explicação do Código\n",
        "\n",
        "1. **`import numpy as np`**:\n",
        "   - **Função**: Importa a biblioteca `numpy`, que é usada para operações numéricas em arrays multidimensionais.\n",
        "   - **Uso**: `numpy` é fundamental para manipulação e processamento de dados numéricos.\n",
        "\n",
        "2. **`import torch`**:\n",
        "   - **Função**: Importa a biblioteca `torch`, que é a base do PyTorch, uma biblioteca para deep learning.\n",
        "   - **Uso**: `torch` fornece tensores e funções para computação eficiente e construção de redes neurais.\n",
        "\n",
        "3. **`import torch.nn.functional as F`**:\n",
        "   - **Função**: Importa o módulo `functional` do submódulo `nn` de PyTorch, que contém funções úteis para operações com redes neurais.\n",
        "   - **Uso**: Funções de ativação, funções de perda e outras operações úteis em modelos de deep learning.\n",
        "\n",
        "4. **`import torchvision`**:\n",
        "   - **Função**: Importa a biblioteca `torchvision`, que fornece ferramentas para carregar e transformar conjuntos de dados de visão computacional.\n",
        "   - **Uso**: Manipulação de dados de imagem, especialmente para uso em redes neurais convolucionais.\n",
        "\n",
        "5. **`import matplotlib.pyplot as plt`**:\n",
        "   - **Função**: Importa o módulo `pyplot` da biblioteca `matplotlib`, usado para visualização de dados.\n",
        "   - **Uso**: Criação de gráficos e visualizações, útil para análise de dados e resultados de modelos.\n",
        "\n",
        "6. **`from time import time`**:\n",
        "   - **Função**: Importa a função `time` do módulo `time`.\n",
        "   - **Uso**: Medir o tempo de execução de trechos de código.\n",
        "\n",
        "7. **`from torchvision import datasets, transforms`**:\n",
        "   - **Função**: Importa os submódulos `datasets` e `transforms` da biblioteca `torchvision`.\n",
        "   - **Uso**: `datasets` fornece acesso a conjuntos de dados populares (como MNIST, CIFAR-10). `transforms` fornece operações para transformar e pré-processar dados de imagem.\n",
        "\n",
        "8. **`from torch import nn, optim`**:\n",
        "   - **Função**: Importa os módulos `nn` e `optim` de PyTorch.\n",
        "   - **Uso**: `nn` é usado para definir camadas e arquiteturas de redes neurais. `optim` é usado para definir otimizadores, que ajustam os parâmetros do modelo durante o treinamento.\n",
        "\n",
        "Este conjunto de importações é comum em scripts de treinamento de modelos de deep learning, especialmente aqueles focados em visão computacional utilizando PyTorch."
      ],
      "metadata": {
        "id": "OOaHm5d_vXv4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "UIhsH0DIupNQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "from torchvision import datasets, transforms\n",
        "from torch import nn, optim\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este código é um exemplo clássico de preparação de dados para treinamento e validação de um modelo de aprendizado de máquina usando o conjunto de dados MNIST, que é amplamente utilizado para a tarefa de classificação de dígitos escritos à mão."
      ],
      "metadata": {
        "id": "Q1GHDcaqvg-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Definindo a conversão de imagem para tensor\n",
        "transform = transforms.ToTensor()\n",
        "\n",
        "# Carrega a parte de treino do dataset\n",
        "trainset = datasets.MNIST('./MNIST_data/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Carrega a parte de validação do dataset\n",
        "valset = datasets.MNIST('./MNIST_data/', download=True, train=False, transform=transform)\n",
        "valloader = torch.utils.data.DataLoader(valset, batch_size=64, shuffle=True)\n"
      ],
      "metadata": {
        "id": "JEsI3QE8vMtp"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Cria um iterador para percorrer os dados de treinamento.\n",
        "- Obtém o próximo lote de imagens e suas respectivas etiquetas.\n",
        "- Visualiza a primeira imagem do lote em escala de cinza.\n",
        "\n",
        "Este processo é útil para inspecionar visualmente os dados e garantir que as transformações e carregamentos foram realizados corretamente."
      ],
      "metadata": {
        "id": "0ek6G4BhwRKl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the correct data loader iterator\n",
        "dataiter = iter(trainloader)\n",
        "\n",
        "# Extract the images and labels\n",
        "imagens, etiquetas = next(dataiter)\n",
        "\n",
        "# Display the first image\n",
        "plt.imshow(imagens[0].numpy().squeeze(), cmap='gray_r')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "mGQNLkFFvpxn",
        "outputId": "cc5636d8-72ce-49d7-85b0-0bad153feb02"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(imagens[0].shape)\n",
        "print(etiquetas[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTbxp26GwSbf",
        "outputId": "de6fbad3-bbe6-4dca-cc8b-a6e28de8e0d9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 28, 28])\n",
            "torch.Size([])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explicação do Código\n",
        "**Importações Necessárias:**\n",
        "- torch.nn: Módulo de PyTorch contendo classes para definir camadas de redes neurais.\n",
        "- torch.nn.functional: Módulo contendo funções úteis como funções de ativação e operações sobre tensores.\n",
        "- __init__: Método inicializador da classe.\n",
        "- super(Modelo, self).__init__(): Chama o inicializador da classe base nn.Module.\n",
        "- self.linear1 = nn.Linear(28*28, 128): Define uma camada totalmente conectada com 784 entradas (28x28 pixels de uma imagem) e 128 saídas.\n",
        "- self.linear2 = nn.Linear(128, 64): Define uma camada totalmente conectada com 128 entradas e 64 saídas.\n",
        "- self.linear3 = nn.Linear(64, 10): Define uma camada totalmente conectada com 64 entradas e 10 saídas.\n",
        "- forward: Método que define o fluxo de dados através da rede.\n",
        "- x = F.relu(self.linear1(x)): Aplica a camada linear1 seguida pela função de ativação ReLU.\n",
        "- x = F.relu(self.linear2(x)): Aplica a camada linear2 seguida pela função de ativação ReLU.\n",
        "- x = self.linear3(x): Aplica a camada linear3 (camada de saída).\n",
        "return F.log_softmax(x, dim=1): Aplica a função de ativação log softmax à saída para obter probabilidades logarítmicas, útil para cálculo de perda em problemas de classificação."
      ],
      "metadata": {
        "id": "2U49KwQNwR8K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Modelo(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Modelo, self).__init__()\n",
        "        self.linear1 = nn.Linear(28*28, 128)  # camada de entrada, 784 neurônios que se ligam a 128\n",
        "        self.linear2 = nn.Linear(128, 64)  # camada interna 1, 128 neurônios que se ligam a 64\n",
        "        self.linear3 = nn.Linear(64, 10)  # camada interna 2, 64 neurônios que se ligam a 10\n",
        "        # para a camada de saída não é necessário definir nada pois só precisamos pegar o output da camada interna 2\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.linear1(x))  # função de ativação da camada de entrada para a camada interna 1\n",
        "        x = F.relu(self.linear2(x))  # função de ativação da camada interna 1 para a camada interna 2\n",
        "        x = self.linear3(x)  # função de ativação da camada interna 2 para a camada de saída, nesse caso f(x) = x\n",
        "        return F.log_softmax(x, dim=1)  # dados utilizados para calcular a perda\n"
      ],
      "metadata": {
        "id": "wdpJXpimzn9w"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este código treina uma rede neural em um conjunto de dados usando o método de descida do gradiente estocástico com retropropagação para minimizar a perda, ajustando os pesos da rede ao longo de várias épocas."
      ],
      "metadata": {
        "id": "dCEIlk8yDUlc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "def treino(modelo, trainloader, device):\n",
        "    otimizador = optim.SGD(modelo.parameters(), lr=0.01, momentum=0.5)  # define a política de atualização dos pesos e da bias\n",
        "    inicio = time()  # timer para sabermos quanto tempo levou o treino\n",
        "\n",
        "    criterio = nn.NLLLoss()  # definindo o critério para calcular a perda\n",
        "    EPOCHS = 10  # número de epochs que o algoritmo rodará\n",
        "    modelo.train()  # ativando o modo de treinamento do modelo\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        perda_acumulada = 0  # inicialização da perda acumulada da epoch em questão\n",
        "\n",
        "        for imagens, etiquetas in trainloader:\n",
        "            imagens = imagens.view(imagens.shape[0], -1)  # convertendo as imagens para \"vetores\" de 28*28 casas para ficarem compatíveis com a entrada da rede\n",
        "            otimizador.zero_grad()  # zerando os gradientes por conta do ciclo anterior\n",
        "\n",
        "            output = modelo(imagens.to(device))  # colocando os dados no modelo\n",
        "            perda_instantanea = criterio(output, etiquetas.to(device))  # calculando a perda da epoch em questão\n",
        "\n",
        "            perda_instantanea.backward()  # backpropagation a partir da perda\n",
        "            otimizador.step()  # atualizando os pesos e as bias\n",
        "\n",
        "            perda_acumulada += perda_instantanea.item()  # atualização da perda acumulada\n"
      ],
      "metadata": {
        "id": "R7a4xX091HGh"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este código define uma função de validação para um modelo de classificação de imagens em PyTorch. Ele avalia a precisão do modelo em um conjunto de dados de validação, comparando as previsões do modelo com as etiquetas corretas e imprimindo a precisão final."
      ],
      "metadata": {
        "id": "wUkCEgEBDVp6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def validação(modelo, valloader, device):\n",
        "    conta_corretas, conta_todas = 0, 0\n",
        "    for imagens, etiquetas in valloader:\n",
        "        for i in range(len(etiquetas)):\n",
        "            img = imagens[i].view(1, 784)\n",
        "\n",
        "            # Desativar o autograd para acelerar a validação. Grafos computacionais dinâmicos têm um custo alto de processamento\n",
        "            with torch.no_grad():\n",
        "                logps = modelo(img.to(device))  # Output do modelo em escala logarítmica\n",
        "\n",
        "            ps = torch.exp(logps)  # Converte output para escala normal (lembrando que é um tensor)\n",
        "            probab = list(ps.cpu().numpy()[0])\n",
        "            etiqueta_pred = probab.index(max(probab))  # Converte o tensor em um número, no caso, o número que o modelo previu como correto\n",
        "            etiqueta_certa = etiquetas.numpy()[i]\n",
        "            if (etiqueta_certa == etiqueta_pred):  # Compara a previsão com o valor correto\n",
        "                conta_corretas += 1\n",
        "            conta_todas += 1\n",
        "\n",
        "    print(\"Total de imagens testadas =\", conta_todas)\n",
        "    print(\"\\nPrecisão do modelo = {:.2f}%\".format(conta_corretas * 100 / conta_todas))\n"
      ],
      "metadata": {
        "id": "BxfXKUvX1Y5L"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este trecho de código é essencial para configurar o ambiente de execução do modelo em PyTorch, garantindo que ele utilize a GPU se disponível, ou a CPU caso contrário. Isso é crucial para acelerar o treinamento e a inferência em redes neurais, já que as GPUs são otimizadas para operações de processamento paralelo, comuns em deep learning."
      ],
      "metadata": {
        "id": "ToGZ-DDjDZjG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelo = Modelo()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "modelo.to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYUTgEWX2Ni4",
        "outputId": "cf3069b7-ae03-471c-949e-e1c131011de0"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Modelo(\n",
              "  (linear1): Linear(in_features=784, out_features=128, bias=True)\n",
              "  (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (linear3): Linear(in_features=64, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    }
  ]
}